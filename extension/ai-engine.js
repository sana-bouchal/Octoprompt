// ========== MOTEUR IA POUR L'ANALYSE DES PROMPTS ==========

class AIEngine {
  constructor() {
    this.apiKey = null;
    this.provider = 'gemini'; // 'gemini' ou 'openai'
    this.model = 'gemini-1.5-flash'; // Mod√®le gratuit de Google
    this.openaiModel = 'gpt-4o-mini';
    this.geminiURL = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent';
    this.openaiURL = 'https://api.openai.com/v1/chat/completions';
  }

  async initialize() {
    return new Promise((resolve) => {
      chrome.storage.sync.get(['apiKey', 'aiProvider'], (result) => {
        this.apiKey = result.apiKey;
        this.provider = result.aiProvider || 'gemini';
        resolve(!!this.apiKey);
      });
    });
  }

  async analyzePrompt(prompt) {
    if (!this.apiKey) {
      console.log('ü§ñ Cl√© API manquante, utilisation du mode r√®gles');
      return null;
    }

    try {
      if (this.provider === 'gemini') {
        return await this.analyzeWithGemini(prompt);
      } else {
        return await this.analyzeWithOpenAI(prompt);
      }
    } catch (error) {
      console.error('‚ùå Erreur lors de l\'analyse IA:', error);
      return null;
    }
  }

  async analyzeWithGemini(prompt) {
    const systemPrompt = `Tu es un expert en prompt engineering. Analyse le prompt suivant et retourne UNIQUEMENT un objet JSON valide avec cette structure exacte :
{
  "score": 75,
  "passedRules": ["R√¥le Sp√©cifique", "Verbes d'Action"],
  "failedRules": ["Format de Sortie", "Audience Cible"],
  "suggestions": [
    "Ajoute un format de sortie pr√©cis (liste, tableau, etc.)",
    "Pr√©cise l'audience cible pour mieux adapter le ton"
  ],
  "improvedPrompt": "Version am√©lior√©e du prompt avec tous les √©l√©ments manquants"
}

Le score doit √™tre entre 0 et 100.
Les r√®gles possibles sont : "R√¥le Sp√©cifique", "Mots-cl√©s de Style", "Longueur Optimale", "Format de Sortie", "Verbes d'Action", "Audience Cible", "Contraintes Sp√©cifiques".
Sois cr√©atif et pertinent dans les suggestions en fran√ßais.
L'improvedPrompt doit √™tre en fran√ßais, coh√©rent avec le prompt original, et vraiment am√©lior√©.

Prompt √† analyser: "${prompt}"`;

    const response = await fetch(`${this.geminiURL}?key=${this.apiKey}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        contents: [{
          parts: [{
            text: systemPrompt
          }]
        }],
        generationConfig: {
          temperature: 0.7,
          maxOutputTokens: 1000,
        }
      })
    });

    if (!response.ok) {
      console.error('‚ùå Erreur Gemini API:', response.status, response.statusText);
      return null;
    }

    const data = await response.json();
    const content = data.candidates?.[0]?.content?.parts?.[0]?.text;
    
    if (!content) {
      console.error('‚ùå Pas de contenu dans la r√©ponse Gemini');
      return null;
    }

    return this.parseAIResponse(content);
  }

  async analyzeWithOpenAI(prompt) {
    const systemPrompt = `Tu es un expert en prompt engineering. Analyse le prompt suivant et retourne UNIQUEMENT un objet JSON valide avec cette structure exacte :
{
  "score": 75,
  "passedRules": ["R√¥le Sp√©cifique", "Verbes d'Action"],
  "failedRules": ["Format de Sortie", "Audience Cible"],
  "suggestions": [
    "Ajoute un format de sortie pr√©cis (liste, tableau, etc.)",
    "Pr√©cise l'audience cible pour mieux adapter le ton"
  ],
  "improvedPrompt": "Version am√©lior√©e du prompt avec tous les √©l√©ments manquants"
}

Le score doit √™tre entre 0 et 100.
Les r√®gles possibles sont : "R√¥le Sp√©cifique", "Mots-cl√©s de Style", "Longueur Optimale", "Format de Sortie", "Verbes d'Action", "Audience Cible", "Contraintes Sp√©cifiques".
Sois cr√©atif et pertinent dans les suggestions.
L'improvedPrompt doit √™tre en fran√ßais, coh√©rent avec le prompt original, et vraiment am√©lior√©.`;

    const response = await fetch(this.openaiURL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.apiKey}`
      },
      body: JSON.stringify({
        model: this.openaiModel,
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: `Prompt √† analyser: "${prompt}"` }
        ],
        temperature: 0.7,
        max_tokens: 1000
      })
    });

    if (!response.ok) {
      console.error('‚ùå Erreur OpenAI API:', response.status, response.statusText);
      return null;
    }

    const data = await response.json();
    const content = data.choices[0]?.message?.content;
    
    if (!content) {
      console.error('‚ùå Pas de contenu dans la r√©ponse OpenAI');
      return null;
    }

    return this.parseAIResponse(content);
  }

  parseAIResponse(content) {
    try {
      // Extraire le JSON de la r√©ponse (au cas o√π il y aurait du texte autour)
      const jsonMatch = content.match(/\{[\s\S]*\}/);
      if (!jsonMatch) {
        console.error('‚ùå Pas de JSON trouv√© dans la r√©ponse');
        return null;
      }

      const analysis = JSON.parse(jsonMatch[0]);
      
      // Validation de la structure
      if (!analysis.score || !analysis.suggestions || !analysis.improvedPrompt) {
        console.error('‚ùå Structure JSON invalide');
        return null;
      }

      console.log('‚úÖ Analyse IA r√©ussie:', analysis);
      return analysis;
    } catch (error) {
      console.error('‚ùå Erreur parsing JSON:', error);
      return null;
    }
  }

  async generateImprovedPrompt(originalPrompt, context = {}) {
    if (!this.apiKey) return null;

    try {
      const systemPrompt = `Tu es un expert en prompt engineering. 
Am√©liore le prompt suivant en le rendant plus clair, pr√©cis et efficace.
Garde le sens original mais enrichis-le avec :
- Un r√¥le sp√©cifique si manquant
- Des verbes d'action clairs
- Un format de sortie d√©fini
- Une audience cible si pertinent
- Des contraintes utiles

Retourne UNIQUEMENT le prompt am√©lior√© en fran√ßais, sans explication.

Prompt √† am√©liorer: ${originalPrompt}`;

      if (this.provider === 'gemini') {
        const response = await fetch(`${this.geminiURL}?key=${this.apiKey}`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            contents: [{
              parts: [{ text: systemPrompt }]
            }],
            generationConfig: {
              temperature: 0.8,
              maxOutputTokens: 500,
            }
          })
        });

        if (!response.ok) return null;
        const data = await response.json();
        return data.candidates?.[0]?.content?.parts?.[0]?.text?.trim();
      } else {
        const response = await fetch(this.openaiURL, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${this.apiKey}`
          },
          body: JSON.stringify({
            model: this.openaiModel,
            messages: [
              { role: 'system', content: systemPrompt },
              { role: 'user', content: originalPrompt }
            ],
            temperature: 0.8,
            max_tokens: 500
          })
        });

        if (!response.ok) return null;
        const data = await response.json();
        return data.choices[0]?.message?.content?.trim();
      }
    } catch (error) {
      console.error('‚ùå Erreur g√©n√©ration IA:', error);
      return null;
    }
  }
}

// Instance globale
const aiEngine = new AIEngine();
