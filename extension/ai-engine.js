// ========== MOTEUR IA POUR L'ANALYSE DES PROMPTS ==========

class AIEngine {
  constructor() {
    this.apiKey = null;
    this.provider = 'gemini'; // 'gemini' ou 'openai'
    this.model = 'gemini-2.5-flash'; // Mod√®le gratuit de Google
    this.openaiModel = 'gpt-4o-mini';
    this.geminiURL = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent';
    this.openaiURL = 'https://api.openai.com/v1/chat/completions';
  }

  async initialize() {
    return new Promise((resolve) => {
      chrome.storage.sync.get(['apiKey', 'aiProvider'], (result) => {
        this.apiKey = result.apiKey;
        this.provider = result.aiProvider || 'gemini';
        resolve(!!this.apiKey);
      });
    });
  }

  async analyzePrompt(prompt) {
    if (!this.apiKey) {
      console.log('ü§ñ Cl√© API manquante, utilisation du mode r√®gles');
      return null;
    }

    try {
      if (this.provider === 'gemini') {
        return await this.analyzeWithGemini(prompt);
      } else {
        return await this.analyzeWithOpenAI(prompt);
      }
    } catch (error) {
      console.error('‚ùå Erreur lors de l\'analyse IA:', error);
      return null;
    }
  }

  async analyzeWithGemini(prompt) {
    const systemPrompt = `Tu es un expert en prompt engineering. Analyse ce prompt et retourne UNIQUEMENT un objet JSON valide sans aucun texte avant ou apr√®s, avec cette structure EXACTE :

{
  "score": 75,
  "passedRules": ["R√¥le Sp√©cifique", "Verbes d'Action"],
  "failedRules": ["Format de Sortie", "Audience Cible"],
  "suggestions": [
    "Ajoute un format de sortie pr√©cis (liste, tableau, JSON, etc.)",
    "Pr√©cise l'audience cible pour adapter le ton"
  ],
  "improvedPrompt": "Version compl√®tement r√©√©crite et am√©lior√©e du prompt original"
}

R√àGLES D'ANALYSE:
- Score: nombre entre 0 et 100 (obligatoire)
- passedRules: liste des r√®gles respect√©es (peut √™tre vide)
- failedRules: liste des r√®gles non respect√©es (peut √™tre vide)
- suggestions: conseils concrets et actionnables (minimum 2)
- improvedPrompt: r√©√©criture compl√®te du prompt en fran√ßais avec tous les √©l√©ments manquants

R√®gles possibles: "R√¥le Sp√©cifique", "Style ou Ton", "Longueur Optimale", "Format de Sortie", "Verbes d'Action", "Audience Cible", "Contraintes Sp√©cifiques"

Prompt √† analyser: "${prompt.replace(/"/g, '\\"')}"

Retourne UNIQUEMENT le JSON, rien d'autre.`;

    const response = await fetch(`${this.geminiURL}?key=${this.apiKey}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        contents: [{
          parts: [{
            text: systemPrompt
          }]
        }],
        generationConfig: {
          temperature: 0.3,
          maxOutputTokens: 2048,
        },
        safetySettings: [
          {
            category: "HARM_CATEGORY_HARASSMENT",
            threshold: "BLOCK_NONE"
          },
          {
            category: "HARM_CATEGORY_HATE_SPEECH",
            threshold: "BLOCK_NONE"
          },
          {
            category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",
            threshold: "BLOCK_NONE"
          },
          {
            category: "HARM_CATEGORY_DANGEROUS_CONTENT",
            threshold: "BLOCK_NONE"
          }
        ]
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('‚ùå Erreur Gemini API:', response.status, response.statusText);
      console.error('D√©tails:', errorText);
      return null;
    }

    const data = await response.json();
    console.log('üì¶ R√©ponse Gemini compl√®te:', JSON.stringify(data, null, 2));
    
    const content = data.candidates?.[0]?.content?.parts?.[0]?.text;
    
    if (!content) {
      console.error('‚ùå Pas de contenu dans la r√©ponse Gemini');
      console.error('Structure re√ßue:', {
        hasCandidates: !!data.candidates,
        candidatesLength: data.candidates?.length,
        firstCandidate: data.candidates?.[0],
        finishReason: data.candidates?.[0]?.finishReason,
        safetyRatings: data.candidates?.[0]?.safetyRatings
      });
      return null;
    }

    return this.parseAIResponse(content);
  }

  async analyzeWithOpenAI(prompt) {
    const systemPrompt = `Tu es un expert en prompt engineering. Analyse le prompt suivant et retourne UNIQUEMENT un objet JSON valide avec cette structure exacte, sans texte avant ou apr√®s :

{
  "score": 75,
  "passedRules": ["R√¥le Sp√©cifique", "Verbes d'Action"],
  "failedRules": ["Format de Sortie", "Audience Cible"],
  "suggestions": [
    "Ajoute un format de sortie pr√©cis (liste, tableau, etc.)",
    "Pr√©cise l'audience cible pour mieux adapter le ton"
  ],
  "improvedPrompt": "Version compl√®tement am√©lior√©e du prompt avec tous les √©l√©ments manquants"
}

R√àGLES:
- Le score DOIT √™tre un nombre entre 0 et 100
- passedRules et failedRules sont des listes de noms de r√®gles
- suggestions doit contenir au moins 2 conseils concrets
- improvedPrompt doit √™tre une r√©√©criture compl√®te en fran√ßais

Les r√®gles possibles sont : "R√¥le Sp√©cifique", "Style ou Ton", "Longueur Optimale", "Format de Sortie", "Verbes d'Action", "Audience Cible", "Contraintes Sp√©cifiques".

Sois cr√©atif et pertinent dans les suggestions. L'improvedPrompt doit √™tre coh√©rent avec le prompt original et vraiment am√©lior√©.

NE RETOURNE QUE LE JSON, rien d'autre.`;

    const response = await fetch(this.openaiURL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.apiKey}`
      },
      body: JSON.stringify({
        model: this.openaiModel,
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: `Prompt √† analyser: "${prompt.replace(/"/g, '\\"')}"` }
        ],
        temperature: 0.3,
        max_tokens: 1000,
        response_format: { type: "json_object" }
      })
    });

    if (!response.ok) {
      console.error('‚ùå Erreur OpenAI API:', response.status, response.statusText);
      return null;
    }

    const data = await response.json();
    const content = data.choices[0]?.message?.content;
    
    if (!content) {
      console.error('‚ùå Pas de contenu dans la r√©ponse OpenAI');
      return null;
    }

    return this.parseAIResponse(content);
  }

  parseAIResponse(content) {
    try {
      // Supprimer les backticks markdown si pr√©sents (avant et apr√®s)
      let cleanContent = content
        .replace(/```json\s*/gi, '')
        .replace(/```\s*/g, '')
        .trim();
      
      // Extraire le JSON de la r√©ponse (accepte les accolades sur plusieurs lignes)
      const jsonMatch = cleanContent.match(/\{[\s\S]*\}/);
      if (!jsonMatch) {
        console.error('‚ùå Pas de JSON trouv√© dans la r√©ponse IA');
        console.log('Contenu re√ßu:', content.substring(0, 200));
        console.log('Contenu nettoy√©:', cleanContent.substring(0, 200));
        return null;
      }

      const analysis = JSON.parse(jsonMatch[0]);
      
      // Validation de la structure avec valeurs par d√©faut
      if (typeof analysis.score === 'undefined' || analysis.score === null) {
        console.error('‚ùå Champ "score" manquant dans la r√©ponse IA');
        console.log('JSON re√ßu:', JSON.stringify(analysis, null, 2));
        return null;
      }

      // Ajouter des valeurs par d√©faut si manquantes
      analysis.passedRules = analysis.passedRules || [];
      analysis.failedRules = analysis.failedRules || [];
      analysis.suggestions = analysis.suggestions || [];
      analysis.improvedPrompt = analysis.improvedPrompt || '';

      // V√©rifier que le score est valide
      if (typeof analysis.score !== 'number' || analysis.score < 0 || analysis.score > 100) {
        console.error('‚ùå Score invalide (doit √™tre entre 0 et 100):', analysis.score);
        return null;
      }

      console.log('‚úÖ JSON pars√© avec succ√®s:', {
        score: analysis.score,
        suggestions: analysis.suggestions.length,
        improvedPrompt: analysis.improvedPrompt ? 'pr√©sent' : 'absent'
      });

      return analysis;
    } catch (error) {
      console.error('‚ùå Erreur parsing JSON:', error.message);
      console.log('Contenu qui a √©chou√©:', content.substring(0, 300));
      return null;
    }
  }

  async generateImprovedPrompt(originalPrompt, context = {}) {
    if (!this.apiKey) return null;

    try {
      const systemPrompt = `Tu es un expert en prompt engineering. 
Am√©liore le prompt suivant en le rendant plus clair, pr√©cis et efficace.
Garde le sens original mais enrichis-le avec :
- Un r√¥le sp√©cifique si manquant
- Des verbes d'action clairs
- Un format de sortie d√©fini
- Une audience cible si pertinent
- Des contraintes utiles

Retourne UNIQUEMENT le prompt am√©lior√© en fran√ßais, sans explication.

Prompt √† am√©liorer: ${originalPrompt}`;

      if (this.provider === 'gemini') {
        const response = await fetch(`${this.geminiURL}?key=${this.apiKey}`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            contents: [{
              parts: [{ text: systemPrompt }]
            }],
            generationConfig: {
              temperature: 0.8,
              maxOutputTokens: 500,
            }
          })
        });

        if (!response.ok) return null;
        const data = await response.json();
        return data.candidates?.[0]?.content?.parts?.[0]?.text?.trim();
      } else {
        const response = await fetch(this.openaiURL, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${this.apiKey}`
          },
          body: JSON.stringify({
            model: this.openaiModel,
            messages: [
              { role: 'system', content: systemPrompt },
              { role: 'user', content: originalPrompt }
            ],
            temperature: 0.8,
            max_tokens: 500
          })
        });

        if (!response.ok) return null;
        const data = await response.json();
        return data.choices[0]?.message?.content?.trim();
      }
    } catch (error) {
      console.error('‚ùå Erreur g√©n√©ration IA:', error);
      return null;
    }
  }
}

// Instance globale
const aiEngine = new AIEngine();
